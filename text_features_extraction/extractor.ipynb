{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(image_data):\n",
    "    \"\"\"\n",
    "    Generates a clinical-style report from the image data.\n",
    "\n",
    "    image_data: Dictionary where keys are image filenames and values are lists of dictionaries \n",
    "                containing 'box' and 'class_label' information.\n",
    "    \"\"\"\n",
    "    reports = {}\n",
    "\n",
    "    for image_id, findings in image_data.items():\n",
    "        if not findings:  # Handle case with no findings\n",
    "            reports[image_id] = \"No abnormalities detected.\"\n",
    "            continue\n",
    "\n",
    "        prompt = f\"Chest X-ray for image {image_id} reveals the following findings:\\n\"\n",
    "        \n",
    "        for finding in findings:\n",
    "            box = finding['box']\n",
    "            class_label = finding['class_label']\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "            \n",
    "            # Create a clinical sentence for each finding\n",
    "            location_desc = f\"between coordinates ({x_min}, {y_min}) and ({x_max}, {y_max})\"\n",
    "            prompt += f\"- {class_label} observed {location_desc}.\\n\"\n",
    "        \n",
    "        prompt += \"No other significant abnormalities detected.\"\n",
    "        reports[image_id] = prompt\n",
    "\n",
    "    return reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = '../segmentation_model/results.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file_path, 'r') as file:\n",
    "    image_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_reports = generate_prompt(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id, report in clinical_reports.items():\n",
    "    # Tokenize the text of the report\n",
    "    inputs = tokenizer(report, return_tensors='pt')\n",
    "    \n",
    "    # Get the text features\n",
    "    with torch.no_grad():\n",
    "        text_features = model(**inputs).last_hidden_state.cpu().numpy().tolist() \n",
    "    \n",
    "    # Save the report and text features in the output data\n",
    "    output_data[image_id] = {\n",
    "        \"report\": report,\n",
    "        \"text_features\": text_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json_path = 'text_features.json'\n",
    "with open(output_json_path, 'w') as outfile:\n",
    "    json.dump(output_data, outfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
