{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhanup6663/chest_x_ray_reporting/blob/main/fasterCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wC-OUyKrvE5M"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OedFfJKavMh0"
      },
      "outputs": [],
      "source": [
        "# !unzip /content/drive/MyDrive/resized_images.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OxhglCCsvZ83"
      },
      "outputs": [],
      "source": [
        "# !pip install bbox_visualizer\n",
        "# !pip install torchvision\n",
        "# !pip install pydicom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fMaChtt8vBHw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import cv2\n",
        "from skimage import io, exposure\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import bbox_visualizer as bbv\n",
        "\n",
        "import pydicom\n",
        "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
        "from glob import glob\n",
        "from skimage import exposure\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import SequentialSampler\n",
        "import torchvision\n",
        "\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from torchvision.ops import box_iou\n",
        "\n",
        "import shutil\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "SIToNwy9vjnl",
        "outputId": "f707828e-27d8-4d16-ea38-60cad7ecb639"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 67914,\n  \"fields\": [\n    {\n      \"column\": \"image_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15000,\n        \"samples\": [\n          \"730ee58d327ab8bcdf8167683c71f565\",\n          \"d8284119d2a86d1f3db93bb6c32272fc\",\n          \"5c9c0490f1629ab3659c7785ae22224d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"Other lesion\",\n          \"Pleural effusion\",\n          \"No finding\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 14,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          9,\n          10,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rad_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"R11\",\n          \"R7\",\n          \"R3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2147723453623191,\n        \"min\": 0.0,\n        \"max\": 0.96923828125,\n        \"num_unique_values\": 20585,\n        \"samples\": [\n          0.2213855421686747,\n          0.2200996677740863,\n          0.1895770392749244\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1913540750150802,\n        \"min\": 0.0,\n        \"max\": 0.9636194029850746,\n        \"num_unique_values\": 19977,\n        \"samples\": [\n          0.6147388059701493,\n          0.5198463508322664,\n          0.515927750410509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2244023718314798,\n        \"min\": 0.0286532951289398,\n        \"max\": 1.0,\n        \"num_unique_values\": 20393,\n        \"samples\": [\n          0.4001439366678661,\n          0.4653614457831325,\n          0.7017401861594497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1997461541137147,\n        \"min\": 0.0342876165113182,\n        \"max\": 1.0,\n        \"num_unique_values\": 20436,\n        \"samples\": [\n          0.415596919127086,\n          0.3616255144032921,\n          0.4171334431630972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 360.8188718961155,\n        \"min\": 823.0,\n        \"max\": 3320.0,\n        \"num_unique_values\": 1036,\n        \"samples\": [\n          3288.0,\n          2469.0,\n          1693.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 297.9594168257485,\n        \"min\": 927.0,\n        \"max\": 3408.0,\n        \"num_unique_values\": 1127,\n        \"samples\": [\n          2244.0,\n          3232.0,\n          2812.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-aae6e1e7-161e-458f-8a1a-1f529ebc6013\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>class_name</th>\n",
              "      <th>class_id</th>\n",
              "      <th>rad_id</th>\n",
              "      <th>x_min</th>\n",
              "      <th>y_min</th>\n",
              "      <th>x_max</th>\n",
              "      <th>y_max</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50a418190bc3fb1ef1633bf9678929b3</td>\n",
              "      <td>No finding</td>\n",
              "      <td>14</td>\n",
              "      <td>R11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2332.0</td>\n",
              "      <td>2580.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21a10246a5ec7af151081d0cd6d65dc9</td>\n",
              "      <td>No finding</td>\n",
              "      <td>14</td>\n",
              "      <td>R7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2954.0</td>\n",
              "      <td>3159.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9a5094b2563a1ef3ff50dc5c7ff71345</td>\n",
              "      <td>Cardiomegaly</td>\n",
              "      <td>3</td>\n",
              "      <td>R10</td>\n",
              "      <td>0.332212</td>\n",
              "      <td>0.588613</td>\n",
              "      <td>0.794712</td>\n",
              "      <td>0.783818</td>\n",
              "      <td>2080.0</td>\n",
              "      <td>2336.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>051132a778e61a86eb147c7c6f564dfe</td>\n",
              "      <td>Aortic enlargement</td>\n",
              "      <td>0</td>\n",
              "      <td>R10</td>\n",
              "      <td>0.548611</td>\n",
              "      <td>0.257986</td>\n",
              "      <td>0.699219</td>\n",
              "      <td>0.353819</td>\n",
              "      <td>2304.0</td>\n",
              "      <td>2880.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>063319de25ce7edb9b1c6b8881290140</td>\n",
              "      <td>No finding</td>\n",
              "      <td>14</td>\n",
              "      <td>R10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2540.0</td>\n",
              "      <td>3072.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aae6e1e7-161e-458f-8a1a-1f529ebc6013')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aae6e1e7-161e-458f-8a1a-1f529ebc6013 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aae6e1e7-161e-458f-8a1a-1f529ebc6013');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a19434a6-4de5-4f73-9dda-2dd8d8f8a167\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a19434a6-4de5-4f73-9dda-2dd8d8f8a167')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a19434a6-4de5-4f73-9dda-2dd8d8f8a167 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                           image_id          class_name  class_id rad_id  \\\n",
              "0  50a418190bc3fb1ef1633bf9678929b3          No finding        14    R11   \n",
              "1  21a10246a5ec7af151081d0cd6d65dc9          No finding        14     R7   \n",
              "2  9a5094b2563a1ef3ff50dc5c7ff71345        Cardiomegaly         3    R10   \n",
              "3  051132a778e61a86eb147c7c6f564dfe  Aortic enlargement         0    R10   \n",
              "4  063319de25ce7edb9b1c6b8881290140          No finding        14    R10   \n",
              "\n",
              "      x_min     y_min     x_max     y_max   width  height  \n",
              "0       NaN       NaN       NaN       NaN  2332.0  2580.0  \n",
              "1       NaN       NaN       NaN       NaN  2954.0  3159.0  \n",
              "2  0.332212  0.588613  0.794712  0.783818  2080.0  2336.0  \n",
              "3  0.548611  0.257986  0.699219  0.353819  2304.0  2880.0  \n",
              "4       NaN       NaN       NaN       NaN  2540.0  3072.0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.read_csv(os.path.join(\"train1.csv\"))\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aPCQD5vWvwQM"
      },
      "outputs": [],
      "source": [
        "dataset_new = dataset[dataset.class_name!='No finding'].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iggGAfGNvzZg"
      },
      "outputs": [],
      "source": [
        "class_brands = {\n",
        "    0: 'Aortic enlargement',\n",
        "    1: 'Atelectasis',\n",
        "    2: 'Calcification',\n",
        "    3: 'Cardiomegaly',\n",
        "    4: 'Consolidation',\n",
        "    5: 'ILD',\n",
        "    6: 'Infiltration',\n",
        "    7: 'Lung Opacity',\n",
        "    8: 'Nodule/Mass',\n",
        "    9: 'Other lesion',\n",
        "    10: 'Pleural effusion',\n",
        "    11: 'Pleural thickening',\n",
        "    12: 'Pneumothorax',\n",
        "    13: 'Pulmonary fibrosis'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7SGwks5Bv6Sp"
      },
      "outputs": [],
      "source": [
        "num_classes = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9FVTXrZSv-yH"
      },
      "outputs": [],
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FastRCNNPredictorWithDropout(nn.Module):\n",
        "    def __init__(self, in_features, num_classes, dropout_p=0.3):\n",
        "        super(FastRCNNPredictorWithDropout, self).__init__()\n",
        "        self.fc = nn.Linear(in_features, in_features)\n",
        "        self.dropout = nn.Dropout(p=dropout_p)\n",
        "        self.cls_score = nn.Linear(in_features, num_classes)\n",
        "        self.bbox_pred = nn.Linear(in_features, num_classes * 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)  # Add dropout here\n",
        "        scores = self.cls_score(x)\n",
        "        bbox_deltas = self.bbox_pred(x)\n",
        "        return scores, bbox_deltas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.roi_heads.box_predictor = FastRCNNPredictorWithDropout(in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "doZNeI7owEmz"
      },
      "outputs": [],
      "source": [
        "def set_device():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    return device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dm-aa2wOwRDL"
      },
      "outputs": [],
      "source": [
        "device=set_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "liDta_KgwBeT"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "params = [p for p in model.parameters() if p.requires_grad]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "boZrW5_zwUZt"
      },
      "outputs": [],
      "source": [
        "def get_train_transform():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.2),\n",
        "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.3),\n",
        "        A.GaussNoise(p=0.2),\n",
        "        A.Rotate(limit=10, p=0.3),\n",
        "        A.OneOf([\n",
        "            A.CLAHE(clip_limit=2),\n",
        "            A.Sharpen(),\n",
        "            A.Emboss(),\n",
        "            A.RandomBrightnessContrast()], p=0.3),\n",
        "        A.RandomScale(scale_limit=0.1, p=0.3), \n",
        "        A.RandomCrop(height=480, width=480, p=0.2),\n",
        "        ToTensorV2() \n",
        "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "\n",
        "def get_valid_transform():\n",
        "    return A.Compose([\n",
        "        ToTensorV2(),\n",
        "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "T-eu3hAWwchf"
      },
      "outputs": [],
      "source": [
        "class LungsAnnotationDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_dir, transforms=None):\n",
        "        super().__init__()\n",
        "        self.image_ids = dataframe['image_id'].unique()\n",
        "        self.df = dataframe\n",
        "        self.image_dir = image_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        image_id = self.image_ids[index]\n",
        "        records = self.df[self.df['image_id'] == image_id]\n",
        "\n",
        "        image = io.imread(f'{self.image_dir}/{image_id}.png')\n",
        "\n",
        "        # Normalize the image\n",
        "        image = image / 255.0  # pixel values are in the range [0, 255]\n",
        "        image = exposure.equalize_hist(image)\n",
        "        image = image.astype('float32')\n",
        "\n",
        "        # If the image has 3 channels already (like RGB), no need to stack, else ensure 3 channels\n",
        "        if image.ndim == 2:  # If the image is grayscale, convert to 3 channels\n",
        "            image = np.stack([image, image, image], axis=-1)\n",
        "\n",
        "        # Ensure the image is in the correct (C, H, W) format\n",
        "        if image.shape[2] == 3:  # Check if image is in (H, W, C)\n",
        "            image = image.transpose(2, 0, 1)  # Convert from (H, W, C) to (C, H, W)\n",
        "\n",
        "        # Get bounding boxes and other details\n",
        "        boxes = records[['x_min', 'y_min', 'x_max', 'y_max']].values\n",
        "\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        area = torch.as_tensor(area, dtype=torch.float32)\n",
        "\n",
        "        labels = records.class_id.values + 1\n",
        "        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
        "            'labels': torch.tensor(labels, dtype=torch.int64),\n",
        "            'area': area,\n",
        "            'iscrowd': iscrowd\n",
        "        }\n",
        "\n",
        "        # Apply transformations if available (pass normalized boxes)\n",
        "        if self.transforms:\n",
        "            sample = {\n",
        "                'image': image,\n",
        "                'bboxes': target['boxes'],\n",
        "                'labels': labels\n",
        "            }\n",
        "            sample = self.transforms(**sample)\n",
        "            image = sample['image']\n",
        "            target['boxes'] = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
        "\n",
        "        # Denormalize boxes AFTER transformations (if you need pixel coordinates)\n",
        "        target['boxes'][:, [0, 2]] = target['boxes'][:, [0, 2]] * 512\n",
        "        target['boxes'][:, [1, 3]] = target['boxes'][:, [1, 3]] * 512\n",
        "\n",
        "        return image, target\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2qmOVz-3wf7R"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    images, targets = zip(*batch)\n",
        "    images = [image.permute(1, 2, 0) if image.shape[0] != 3 else image for image in images]\n",
        "    return torch.stack(images), targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AFd5IrABws5T"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = None\n",
        "\n",
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "X8LmdZCUwv0h"
      },
      "outputs": [],
      "source": [
        "class Averager:\n",
        "    def __init__(self):\n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0\n",
        "\n",
        "    def send(self, value):\n",
        "        self.current_total += value\n",
        "        self.iterations += 1\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        if self.iterations == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1.0 * self.current_total / self.iterations\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model, fold, epoch):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "            # Save model checkpoint as the best so far\n",
        "            checkpoint_path = f\"model_fasterRCNN_fold{fold}_best.pth\"\n",
        "            print(f\"Validation improved, saving model at epoch {epoch}...\")\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            shutil.copy(checkpoint_path, f'/content/drive/MyDrive/x_ray_models/{checkpoint_path}')\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "10uhzItILu6t"
      },
      "outputs": [],
      "source": [
        "def calculate_iou(pred_boxes, gt_boxes):\n",
        "    \"\"\"\n",
        "    Calculate IoU (Intersection over Union) between predicted and ground truth boxes.\n",
        "\n",
        "    Args:\n",
        "        pred_boxes (Tensor): Predicted bounding boxes, shape [num_pred_boxes, 4].\n",
        "        gt_boxes (Tensor): Ground truth bounding boxes, shape [num_gt_boxes, 4].\n",
        "\n",
        "    Returns:\n",
        "        Tensor: IoU scores, shape [num_pred_boxes, num_gt_boxes].\n",
        "    \"\"\"\n",
        "    return box_iou(pred_boxes, gt_boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TZTF1vVlwkcZ"
      },
      "outputs": [],
      "source": [
        "def train_model(train_dataset, val_dataset, fold, start_epoch=0, resume=False, checkpoint_path=None):\n",
        "    # Initialize data loaders\n",
        "    train_data_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=10,\n",
        "        shuffle=True, \n",
        "        num_workers=4,\n",
        "        collate_fn=collate_fn,\n",
        "        prefetch_factor=4\n",
        "    )\n",
        "\n",
        "    val_data_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=3,\n",
        "        shuffle=False,\n",
        "        num_workers=4,\n",
        "        collate_fn=collate_fn,\n",
        "        prefetch_factor=4\n",
        "    )\n",
        "\n",
        "    # Initialize Averager instances for loss tracking\n",
        "    loss_hist = Averager()\n",
        "    val_loss_hist = Averager()\n",
        "\n",
        "    # Initialize optimizer and scheduler\n",
        "    optimizer = torch.optim.AdamW(params, lr=0.0005, weight_decay=0.0005,betas=(0.9, 0.999), eps=1e-08)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.5, verbose=True)\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(patience=10)\n",
        "\n",
        "    # Resume from checkpoint\n",
        "    if resume and checkpoint_path:\n",
        "        print(f\"Resuming training from checkpoint {checkpoint_path}...\")\n",
        "        model.load_state_dict(torch.load(checkpoint_path))\n",
        "    \n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        loss_hist.reset()\n",
        "        model.train()\n",
        "\n",
        "        for itr, (images, targets) in enumerate(train_data_loader, 1):\n",
        "            optimizer.zero_grad()\n",
        "            images = [image.to(device) for image in images]\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            loss_dict = model(images, targets)\n",
        "\n",
        "            # Calculate the loss\n",
        "            if isinstance(loss_dict, dict):\n",
        "                loss_classifier = loss_dict['loss_classifier']\n",
        "                loss_box_reg = loss_dict['loss_box_reg']\n",
        "                loss_objectness = loss_dict['loss_objectness']\n",
        "                loss_rpn_box_reg = loss_dict['loss_rpn_box_reg']\n",
        "\n",
        "                losses = (loss_objectness +\n",
        "                          10 * loss_classifier +\n",
        "                          10 * loss_rpn_box_reg +\n",
        "                          0.5 * loss_box_reg ** 2)\n",
        "\n",
        "                loss_value = losses.item()\n",
        "                loss_hist.send(loss_value)\n",
        "                losses.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            if itr % 100 == 0:\n",
        "                print(f\"Fold #{fold} Epoch #{epoch+1} Iteration #{itr}/{len(train_data_loader)} loss: {loss_hist.value:.4f}\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            iou_hist = Averager()\n",
        "            for images, targets in val_data_loader:\n",
        "                images = [image.to(device) for image in images]\n",
        "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "                outputs = model(images)\n",
        "                for output, target in zip(outputs, targets):\n",
        "                    pred_boxes = output['boxes']\n",
        "                    gt_boxes = target['boxes']\n",
        "                    iou = calculate_iou(pred_boxes, gt_boxes)\n",
        "                    iou_hist.send(iou.mean().item())\n",
        "\n",
        "            avg_iou = iou_hist.value\n",
        "            print(f\"Fold #{fold} Epoch #{epoch+1} Validation IoU: {avg_iou:.4f}\")\n",
        "\n",
        "            # Class-wise detection statistics (modify for your dataset)\n",
        "            print(f\"Validation Stats for Fold #{fold}:\")\n",
        "            for i, class_name in enumerate(['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity', 'No Finding', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis']):\n",
        "                print(f\"{class_name:30} | {avg_iou:8f} | {len(val_data_loader)}\")\n",
        "\n",
        "        scheduler.step(avg_iou)\n",
        "        \n",
        "        # Early stopping check\n",
        "        early_stopping(avg_iou, model, fold, epoch)\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        # Save model checkpoint every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            checkpoint_path = f\"model_fasterRCNN_fold{fold}_epoch{epoch+1}.pth\"\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            shutil.copy(checkpoint_path, f'/content/drive/MyDrive/x_ray_models/{checkpoint_path}')\n",
        "\n",
        "    # Save final model state\n",
        "    final_model_path = f\"model_fasterRCNN_fold{fold}_final.pth\"\n",
        "    torch.save(model.state_dict(), final_model_path)\n",
        "    shutil.copy(final_model_path, f'/content/drive/MyDrive/x_ray_models/{final_model_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OIni_SQHw_o0"
      },
      "outputs": [],
      "source": [
        "DIR_TRAIN = os.path.join( \"resized_images\")\n",
        "\n",
        "# train_df, valid_df = train_test_split(dataset_new, test_size=0.20, random_state=42)\n",
        "\n",
        "# train_dataset = LungsAnnotationDataset(train_df, DIR_TRAIN,get_train_transform())\n",
        "# valid_dataset = LungsAnnotationDataset(valid_df, DIR_TRAIN,get_valid_transform())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37uq0pJowxoy",
        "outputId": "ddc882fe-15ec-495f-8755-d2a4be8d50d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold #1 Epoch #1 Iteration #100/352 loss: 4.4094\n",
            "Fold #1 Epoch #1 Iteration #200/352 loss: 4.0404\n",
            "Fold #1 Epoch #1 Iteration #300/352 loss: 3.9320\n",
            "Fold #1 Epoch #1 Validation IoU: 0.0613\n",
            "Fold #1 Epoch #2 Iteration #100/352 loss: 3.3825\n",
            "Fold #1 Epoch #2 Iteration #200/352 loss: 3.4401\n",
            "Fold #1 Epoch #2 Iteration #300/352 loss: 3.4508\n"
          ]
        }
      ],
      "source": [
        "k = 1\n",
        "df = dataset_new.sample(frac=1).reset_index(drop=True)\n",
        "kfold = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Get the target classes (class_id) and the groups (image_id)\n",
        "X = dataset_new['image_id'].values\n",
        "y = dataset_new['class_id'].values\n",
        "groups = dataset_new['image_id'].values\n",
        "\n",
        "for train_index, val_index in kfold.split(X, y, groups):\n",
        "    train_df = dataset_new.loc[train_index].reset_index(drop=True)\n",
        "    valid_df = dataset_new.loc[val_index].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = LungsAnnotationDataset(train_df, DIR_TRAIN, get_train_transform())\n",
        "    val_dataset = LungsAnnotationDataset(valid_df, DIR_TRAIN, get_valid_transform())\n",
        "\n",
        "    # Train and validate the model\n",
        "    train_model(train_dataset, val_dataset, k)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNj3mDMoEiRnu2NrIjkBVc9",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.12.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
